fit <- rpart(S$yesno~ ., data=S, subset=sub)
plot(fit)
text(fit)
table(predict(fit, S[-sub,], type="class"), S[-sub, "yesno"])
S<-spam7
sub <- c(sample(1:max(which(S$yesno=="y")), round(0.8*max(which(S$yesno=="y")),digits=0)),
sample((max(which(S$yesno=="y"))+1):4601,round(0.8*length(which(S$yesno=="n")),digits=0)))
fit <- rpart(S$yesno~ ., data=S, subset=sub)
plot(fit)
text(fit)
table(predict(fit, S[-sub,], type="class"), S[-sub, "yesno"])
S<-spam7
sub <- c(sample(1:max(which(S$yesno=="y")), round(0.8*max(which(S$yesno=="y")),digits=0)),
sample((max(which(S$yesno=="y"))+1):4601,round(0.8*length(which(S$yesno=="n")),digits=0)))
fit <- rpart(S$yesno~ ., data=S, subset=sub)
plot(fit)
text(fit)
table(predict(fit, S[-sub,], type="class"), S[-sub, "yesno"])
S<-spam7
sub <- c(sample(1:max(which(S$yesno=="y")), round(0.8*max(which(S$yesno=="y")),digits=0)),
sample((max(which(S$yesno=="y"))+1):4601,round(0.8*length(which(S$yesno=="n")),digits=0)))
fit <- rpart(S$yesno~ ., data=S, subset=sub)
fit
plot(fit)
text(fit)
S<-spam7
sub <- c(sample(1:max(which(S$yesno=="y")), round(0.8*max(which(S$yesno=="y")),digits=0)),
sample((max(which(S$yesno=="y"))+1):4601,round(0.8*length(which(S$yesno=="n")),digits=0)))
fit <- rpart(S$yesno~ ., data=S, subset=sub)
fit
plot(fit)
text(fit)
table(predict(fit, S[-sub,], type="class"), S[-sub, "yesno"])
predict(fit, S[-sub,], type="class"), S[-sub, "yesno"]
(24+110)/(534+253)
(24+110)/(921)
(55+72)/(921)
S<-spam7
sub <- c(sample(1:max(which(S$yesno=="y")), round(0.8*max(which(S$yesno=="y")),digits=0)),
sample((max(which(S$yesno=="y"))+1):4601,round(0.8*length(which(S$yesno=="n")),digits=0)))
fit <- rpart(S$yesno~ ., data=S, subset=sub)
fit
plot(fit)
text(fit)
table(predict(fit, S[-sub,], type="class"), S[-sub, "yesno"])
(145)/(921)
# Packages needed (not exhaustive list):
# factoextra, Hmisc, tidyverse, Nbclust, ggplot2, plotrix,corrplot,
# sm, zoo, vioplot
# uncomment the following cmd to install one of them, if needed :
# install.packages("package_name")
# example : install.packages("plotrix")
#
################################################################################
# STEP 1 : DATA PREPARATION
################################################################################
getwd()
setwd("/home/liz/Documents/MS_Big_Data_TP_et_projets/Data Mining/Projet/Parkinson_R")
P_init<-read.table("parkinsons.data", header = FALSE, sep = ",", quote = "", dec = ".",
row.names=1, col.names=c("Signal_Id","MDVP_Fo", "MDVP_Fhi", "MDVP_Flow","MDVP_JitterRel",
"MDVP_JitterAbs","MDVP_Rap","MDVP_PPQ","Jitter_DDP",
"MDVP_Shimmer","MDVP_ShimmerDB","Shimmer_APQ3",
"Shimmer_APQ5","MDVP_APQ","Shimmer_DDA","NHR","HNR",
"status","RPDE","DFA","spread1","spread2",
"D2","PPE"),
as.is = FALSE, na.strings = "NA",
colClasses = NA, nrows = -1,
skip = 1, check.names = TRUE, fill = !TRUE,
strip.white = FALSE, blank.lines.skip = TRUE,
comment.char = "#")
# je vérifie le bon nommage des attributs/individus, la dim, le type des attributs
rownames(P_init)    # lines
colnames(P_init)    # columns
names(P_init)       # attributes
dim(P_init)         # dim
str(P_init)         # types
# stats complémentaires
# infos sur le nb d'observations, sur l'existence de val manquantes,
# et autres quantiles
library(Hmisc)
#boxplot d'attributs de même ordre de grandeur
boxplot(P_init[,c('MDVP_Fo', 'MDVP_Fhi', 'MDVP_Flow')],
col = c("yellow"),           #Pour la couleur
main = paste("MDVP Frequencies Boxplot"),     #Pour le titre
ylab = "Quantiles")          #Pour le titre de l’axe des ordonnées
# camembert 3d pour attribut binaire
# permet de visualiser le ratio des signaux de patients sains vs malades
library(plotrix)
mytable <- table(P_init$status)
names(mytable)
lbls <- paste(c("Healthly", "Parkinson Disease"), "\n",mytable, sep="")
pie3D(mytable, col=c("purple","#dd00dd"), labels = lbls, explode=0.1,
main="Nb of signals corresponding \n with status patient")
# Split des données patients malades vs.sains pour voir si les outliers seraient
# en lien avec le caractère malade du patient
# P_pd est le dataset contenant les signaux de patients malades
P_pd <- P_init[P_init$status==1,]
describe(P_pd)
# P_h est le dataset contenant les signaux de patients malades
P_h <- P_init[P_init$status==0,]
describe(P_h)
#boxplot de l'attribut MDVP_ShimmerDB en comparant le dataset d'origine,
# celui des patients malades, puis celui des patients sains
boxplot(P_init$MDVP_ShimmerDB, P_pd$MDVP_ShimmerDB, P_h$MDVP_ShimmerDB,
col = c("purple"),           #Pour la couleur
main = paste("MDVP_ShimmerDB Boxplot"),     #Pour le titre
names = c("all", "PD", "healthly"), #Pour le labelling de l'axe x
ylab = "Quantiles")          #Pour le titre de l’axe des ordonnées
#boxplot d'attributs (regroupements avec attributs de même ordre de grandeur)
boxplot(P_init[,c('RPDE','DFA','spread2')],
col = c("pink"),           #Pour la couleur
main = paste("RPDE, DFA, spread2 and PPE Boxplot"),     #Pour le titre
ylab = "Quantiles")          #Pour le titre de l’axe des ordonnées
#boxplot de l'attribut PPE en comparant le dataset d'origine,
# celui des patients malades, puis celui des patients sains
boxplot(P_init$PPE, P_pd$PPE, P_h$PPE,
col = c("purple"),           #Pour la couleur
main = paste("PPE Boxplot"),     #Pour le titre
names = c("all", "PD", "healthly"), #Pour le labelling de l'axe x
ylab = "Quantiles")          #Pour le titre de l’axe des ordonnées
#boxplot de l'attribut MDVP_ShimmerDB en comparant le dataset d'origine,
# celui des patients malades, puis celui des patients sains
boxplot(P_init$MDVP_ShimmerDB, P_pd$MDVP_ShimmerDB, P_h$MDVP_ShimmerDB,
col = c("purple"),           #Pour la couleur
main = paste("MDVP_ShimmerDB Boxplot"),     #Pour le titre
names = c("all", "PD", "healthly"), #Pour le labelling de l'axe x
ylab = "Quantiles")          #Pour le titre de l’axe des ordonnées
boxplot(P_init$MDVP_JitterAbs, P_pd$MDVP_JitterAbs, P_h$MDVP_JitterAbs,
col = c("purple"),           #Pour la couleur
main = paste("MDVP_JitterAbs Boxplot"),     #Pour le titre
names = c("all", "PD", "healthly"), #Pour le labelling de l'axe x
ylab = "Quantiles")          #Pour le titre de l’axe des ordonnées
# on voit ci-dessous que le caractère malade ne change pas vraiment l'occurence
# d'outliers
boxplot(P_init$Jitter_DDP, P_pd$Jitter_DDP, P_h$Jitter_DDP,
col = c("purple"),           #Pour la couleur
main = paste("Jitter_DDP Boxplot"),     #Pour le titre
names = c("all", "PD", "healthly"), #Pour le labelling de l'axe x
ylab = "Quantiles")          #Pour le titre de l’axe des ordonnées
# a spliter
#boxplot d'attributs de même ordre de grandeur
boxplot(P_init[,c('MDVP_JitterRel','MDVP_Rap','MDVP_PPQ')],
col = c("pink"),           #Pour la couleur
main = paste("Boxplot"),     #Pour le titre
ylab = "Quantiles")          #Pour le titre de l’axe des ordonnées
# a spliter
#boxplot d'attributs de même ordre de grandeur
boxplot(P_init[,c('MDVP_Shimmer','Shimmer_APQ3',
'Shimmer_APQ5','MDVP_APQ','Shimmer_DDA','NHR')],
col = c("pink"),           #Pour la couleur
main = paste("Boxplot"),     #Pour le titre
ylab = "Quantiles")          #Pour le titre de l’axe des ordonnées
#boxplot d'attributs de même ordre de grandeur
boxplot(P_init[,c('spread1')],
col = c("green"),           #Pour la couleur
main = paste("Spread1 Boxplot"),     #Pour le titre
ylab = "Quantiles")          #Pour le titre de l’axe des ordonnées
#boxplot d'attributs de même ordre de grandeur
boxplot(P_init[,c('D2')],
col = c("blue"),           #Pour la couleur
main = paste("D2 Boxplot"),     #Pour le titre
ylab = "Quantiles")          #Pour le titre de l’axe des ordonnées
#boxplot d'attributs de même ordre de grandeur
boxplot(P_init$HNR,
col = c("yellow"),           #Pour la couleur
main = paste("HNR"),     #Pour le titre
sub= paste("Boxplot"),      # pour le sous-titre
ylab = "Quantiles")         #Pour le titre de l’axe des ordonnées
# graphique en ligne de crêtes, exemple avec HNR et D2
# Libraries
library(sm)
library(zoo)
library(ggplot2)
library(vioplot)
vioplot( P_pd$HNR, P_pd$D2, col = "palevioletred", plotCentre = "line",
side = "left",  names=c("HNR", "D2"))
vioplot(P_h$HNR, P_h$D2 , data = P_h, col = "lightblue", plotCentre = "line",
side = "right", add = T)
legend("bottomright", fill = c("palevioletred", "lightblue"), legend = c("PD",
"Healthly"), title = "Status")
# jenleve le status
P_stless <- P_init[ , -17]
P_stless
# mat de correlation (coeff de Peason par defaut)
Mcor_P_stless <- round(cor(P_stless),2)
View(Mcor_P_stless)
# heatmap
library(corrplot)
corrplot(Mcor_P_stless, type="upper", order="hclust", tl.col="black", tl.srt=45)
################################################################################
# Fondre la matrice de corrélation
library(reshape2)
melted_cormat <- melt(Mcor_P_stless)
library(ggplot2)
ggplot(data = melted_cormat, aes(x=Var1, y=Var2, fill=value)) +
geom_tile()
# Obtenir le triangle inférieur
get_lower_tri<-function(Mcor_P_stless){
Mcor_P_stless[upper.tri(Mcor_P_stless)] <- NA
return(Mcor_P_stless)
}
# Obtenir le triangle supérieur
get_upper_tri <- function(Mcor_P_stless){
Mcor_P_stless[lower.tri(Mcor_P_stless)]<- NA
return(Mcor_P_stless)
}
#utilisation
upper_tri <- get_upper_tri(Mcor_P_stless)
upper_tri
# Fondre la matrice de corrélation
melted_cormat <- melt(upper_tri, na.rm = TRUE)
library(ggplot2)
ggplot(data = melted_cormat, aes(Var2, Var1, fill = value))+
geom_tile(color = "white")+
scale_fill_gradient2(low = "blue", high = "red", mid = "white",
midpoint = 0, limit = c(-1,1), space = "Lab",
name="Pearson\nCorrelation") +
theme_minimal()+
theme(axis.text.x = element_text(angle = 45, vjust = 1,
size = 12, hjust = 1))+
coord_fixed()
reorder_cormat <- function(Mcor_P_stless){
# Utiliser la corrélation entre les variables
# comme mésure de distance
dd <- as.dist((1-Mcor_P_stless)/2)
hc <- hclust(dd)
Mcor_P_stless <-Mcor_P_stless[hc$order, hc$order]
}
# Reordonner la matrice de corrélation
Mcor_P_stless <- reorder_cormat(Mcor_P_stless)
upper_tri <- get_upper_tri(Mcor_P_stless)
# Fondre la matrice de corrélation
melted_cormat <- melt(upper_tri, na.rm = TRUE)
# Créer un ggheatmap
ggheatmap <- ggplot(melted_cormat, aes(Var2, Var1, fill = value))+
geom_tile(color = "white")+
scale_fill_gradient2(low = "blue", high = "red", mid = "white",
midpoint = 0, limit = c(-1,1), space = "Lab",
name="Pearson\nCorrelation") +
theme_minimal()+ # minimal theme
theme(axis.text.x = element_text(angle = 45, vjust = 1,
size = 12, hjust = 1))+
coord_fixed()
# Afficher heatmap
print(ggheatmap)
ggheatmap +
geom_text(aes(Var2, Var1, label = value), color = "black", size = 4) +
theme(
axis.title.x = element_blank(),
axis.title.y = element_blank(),
panel.grid.major = element_blank(),
panel.border = element_blank(),
panel.background = element_blank(),
axis.ticks = element_blank(),
legend.justification = c(1, 0),
legend.position = c(0.6, 0.7),
legend.direction = "horizontal")+
guides(fill = guide_colorbar(barwidth = 7, barheight = 1,
title.position = "top", title.hjust = 0.5))
#library(ggplot2)
# utiliser une heatmap : il faut transformer le dataframe em matrice
M_init <- as.matrix(P_init, rownames.force = TRUE)
# je vérifie le type
class(M_init)
class(P_init)
################################################################################
# STEP 3 : EXPLORATING ANALYSIS
################################################################################
#
# STEP 3. 1 CLASSIFICATION NON SUPERVISEE
################################################################################
library(tidyverse)
#
# je m'assure que toutes les données sont définies
all(!is.na(P_init))
# si il y en a une qui ne l'est pas, je cherche laquelle
lapply(P_init,function(x) which(is.na(x)))
# standardisation des données
P_initsc<-scale(P_init)
P_hsc<-scale(P_h)
P_pdsc<-scale(P_pd)
#affichage boite à moustaches centré réduit
boxplot(P_initsc)
boxplot(P_hsc)
boxplot(P_pdsc)
label<-attributes(P_initsc)$dimnames[[1]]
plot(P_initsc, type="n")
text(P_initsc,label)
# Algo kmeans sur 2 clusters
fit.P2<-kmeans(P_initsc,4, 25)
fit.P2
str(fit.P2)
fit.P2$withinss
fit.P2$tot.withinss
# within cluster sum of squares by cluster (WCSSC)
# squared average distance of all the points within a cluster to the cluster centroid
fit.P2$tot.withinss/fit.P2$totss
#between cluster sum of squares (BSSC)
# squared average distance of all the points within a cluster to the cluster centroid
fit.P2$betweenss/fit.P2$totss
# visualisation 2d - donc totalement imcomplète - des 4 clusters Kmeans
library(NbClust)
fviz_cluster(fit.P2, data = P_initsc)
plot(P_initsc, col = P2$cluster)
points(P2$centers, col = 1:5, pch = 8)
# visualisation 2d - donc totalement imcomplète - des 4 clusters Kmeans
library(factoextra)
library(NbClust)
fviz_cluster(fit.P2, data = P_initsc)
plot(P_initsc, col = P2$cluster)
points(P2$centers, col = 1:5, pch = 8)
library(factoextra)
library(NbClust)
#Tracé de la fonction du courde
# se base sur les distances intraclusters
{
Tab<- NULL
for(k in 1:10){
Res<-kmeans(P_initsc,k)
Tab[k]= Res$tot.withinss/Res$totss
}
plot(Tab, typ='l')
}
# Tracé de la valeur silhouette
# se base sur L'analyse des silhouettes peut être utilisée pour étudier la
# distance de séparation entre les clusters résultants.Le tracé de la silhouette
#affiche une mesure de la proximité de chaque point d'un cluster par rapport aux
#points des clusters voisins et fournit ainsi un moyen d'évaluer visuellement des
# paramètres tels que le nombre de clusters.Cette mesure a une plage de [-1,1].
fviz_nbclust(P_initsc, kmeans, method = "silhouette")+
labs(subtitle = "Silhouette method")
#la silhouette max ne dépasse pas 0,4 pour k=2, les autres val de k sont en dessous de 0,25
# "il faut retourner sur les données"
# Gap statistic
# nboot = 50 to keep the function speedy.
# recommended value: nboot= 500 for your analysis.
# Use verbose = FALSE to hide computing progression.
set.seed(123)
fviz_nbclust(P_initsc, kmeans, nstart = 25, method = "gap_stat", nboot = 50)+
labs(subtitle = "Gap statistic method")
# visu des clusters
km.out2=kmeans(P_initsc,centers=2,nstart =20)
km.out2
pairs(P_initsc, col=c(1:2)[km.out2$cluster])
km.out$cluster
# coord des centroïdes
km.out=kmeans(P_initsc,centers=4,nstart =20)
km.out$centers
# acp
# visu des val aberrantes !
fviz_cluster(km.out2, P_initsc, ellipse.type = "norm")
# CAH
################################################################################
DP_sc <- dist(P_initsc)
# méthode WARD (basée sur les variances)
reshcW <- hclust(DP_sc, method="ward.D2")  # pour qu'on ait des variances comparables
plot(reshcW) #pour avoir des classes homogènes en terme de variance, D2 joue selon
# méthode MIN (on dit "single")
reshcMIN <- hclust(DP_sc, method="single")
plot(reshcMIN)
# méthode MAX (on dit "complete")
reshcMAX <- hclust(DP_sc, method="conplete")
plot(reshcMAX)
# méthode MEAN (on dit "average")
reshcMEAN <- hclust(DP_sc, method="average")
plot(reshcMEAN)
# Multidimensional Scaling Analysis (doit toujours être faite à la fin des plot)
# permet de vérifier que les classes correspondent à ce qu'on voit sur les dendogrammes
CordTP3<-cmdscale(DP_sc, k=3)
label3<-attributes(CordTP3)$dimnames[[1]]
plot(CordTP3[,1],CordTP3[,3], type="n")
text(CordTP3[,1],CordTP3[,3],label3,cex=0.7)
# Algo PAM
################################################################################
library(cluster)
Respam2 <- pam(DP_sc,2)
plot(Respam2)
Respam2
Respam3 <- pam(DP_sc,4)
plot(Respam3)
Respam2
# le résultat des objective function build et swap sont peu différents donc
# l'optimisation par swap est faible !
Respam2$silinfo
# on va essayer les mêmes algos en réduisant du mieux possible la dimension
# REDUC DIM
#########################################
##
## PCA : va permettre de passer de 22 à 5 dimension, ce qui permettra de faire
## une regression logistique sans trop de souci car nb individu doit être > nb d'attributs * 10
#
# Mode d'emploi : http://www.sthda.com/french/articles/38-methodes-des-composantes-principales-dans-r-guide-pratique/73-acp-analyse-en-composantes-principales-avec-r-l-essentiel/#packages-r
#
library("FactoMineR")
res.pca <- PCA(P_initsc, scale.unit = TRUE, graph = TRUE)
print(res.pca)
# desc des val propres portant le plus l'information
library("factoextra")
eig.val <- get_eigenvalue(res.pca)
eig.val
# a priori 5 dimensuions suffisent (87% de l'info, c'est bien)
# graphique des val propres
fviz_eig(res.pca, addlabels = TRUE, ylim = c(0, 50))
var <- get_pca_var(res.pca)
var
head(var$cos2, 10)
var$cos2
# graphique des var
library("corrplot")
corrplot(var$cos2, is.corr=FALSE)
# Cos2 total des variables sur Dim.1 et Dim.2
fviz_cos2(res.pca, choice = "var", axes = 1:2)
# Colorer en fonction du cos2: qualité de représentation
fviz_pca_var(res.pca, col.var = "cos2",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
repel = TRUE # Évite le chevauchement de texte
)
#
#Contributions des variables aux axes principaux
head(var$contrib, 4)
var$contrib
# on voit que DFA, MDVP_Fo, PRDE ont des gros coeff contributeurs aux nouveaux composants
library("corrplot")
corrplot(var$contrib, is.corr=FALSE)
# Contributions des variables à PC1
fviz_contrib(res.pca, choice = "var", axes = 1, top = 10)
# Contributions des variables à PC2
fviz_contrib(res.pca, choice = "var", axes = 2, top = 10) # MDVP_Fo et MDVP_Flow surpassent toutes les autres
# Contributions des variables à PC3
fviz_contrib(res.pca, choice = "var", axes = 3, top = 10) # D2, DFA, spread2...
# Contributions des variables à PC1
fviz_contrib(res.pca, choice = "var", axes = 1, top = 10)
# Contributions des variables à PC2
fviz_contrib(res.pca, choice = "var", axes = 2, top = 10) # MDVP_Fo et MDVP_Flow surpassent toutes les autres
# Contributions des variables à PC3
fviz_contrib(res.pca, choice = "var", axes = 3, top = 10) # D2, DFA, spread2...
# Contributions des variables à PC4
fviz_contrib(res.pca, choice = "var", axes = 4, top = 10) # DFA, Shimmet_APQ5
# Contributions des variables à PC5
fviz_contrib(res.pca, choice = "var", axes = 5, top = 10) # RPDE, DFA, spread2
fviz_pca_var(res.pca, col.var = "contrib",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07")
)
#autre essai de combinaison pca (sur matrice de corrélation!! contrairement à prcomp et PCA) /
# a priori, le scaling n'est pas nécessaire car l'ACP/reg log s'intéresse  aux corrélations
#https://online.stat.psu.edu/stat857/node/130/
predictorX <- M_init[ , -17]
responseY <- M_init[, 17]
pca <- princomp(predictorX, cor=T) # principal components analysis using correlation matrix
pc.comp <- pca$scores
pca$scores
pc.comp1 <- 1*pc.comp[,1] # principal component 1 scores (negated for convenience)
pc.comp1 <- 1*pc.comp[,1] # principal component 1 scores (negated for convenience)
pc.comp2 <- 1*pc.comp[,2] # principal component 2 scores (negated for convenience)
pc.comp3 <- 1*pc.comp[,3] # principal component 1 scores (negated for convenience)
pc.comp4 <- 1*pc.comp[,4] # principal component 2 scores (negated for convenience)
pc.comp5 <- 1*pc.comp[,5] # principal component 1 scores (negated for convenience)
# logistic regression
# construction modèle
pc.comp_df <- as.data.frame(pc.comp)
model_logistic <- glm(responseY~pc.comp1+pc.comp2+pc.comp3+pc.comp4+pc.comp5, data= pc.comp_df, family=binomial("logit"))
model_logistic <- glm(responseY~pc.comp1+pc.comp2+pc.comp3+pc.comp4+pc.comp5, data= pc.comp_df, family=binomial("logit"))
# prédiction
glm.probs <- predict(model_logistic,type = "response")
glm.preds <- ifelse(glm.probs > 0.5,1,0)
# Accuracy
table(glm.preds,responseY)
mean(glm.preds == responseY)
#training
train <- pc.comp[1:150,1:5]
train1 <- -1*train[,1] # principal component 1 scores (negated for convenience)
train2 <- -1*train[,2] # principal component 2 scores (negated for convenience)
train3  <- -1*train[,3] # principal component 1 scores (negated for convenience)
train4 <- -1*train[,4] # principal component 2 scores (negated for convenience)
train5 <- -1*train[,5]
train_df <- as.data.frame(train)
responseYtrain <- M_init[1:150, 17]
responseYtrain
glm.fit <- glm(responseY~pc.comp1+pc.comp2+pc.comp3+pc.comp4+pc.comp5, data= train_df, family=binomial("logit"))
#glm.fit <- glm(responseYtrain~train1+train2+train3+train4+train5, family=binomial("logit"))
glm.probs <- predict(glm.fit,type = "response")
glm.preds <- ifelse(glm.probs > 0.5,1,0)
# Accuracy
table(glm.preds,responseYtrain)
mean(glm.preds == responseYtrain)
glm.fit <- glm(responseY~train1+train2+train3+train4+train5, data= train_df, family=binomial("logit"))
glm.fit <- glm(responseYtrain~train1+train2+train3+train4+train5, data= train_df, family=binomial("logit"))
#glm.fit <- glm(responseYtrain~train1+train2+train3+train4+train5, family=binomial("logit"))
glm.probs <- predict(glm.fit,type = "response")
glm.preds <- ifelse(glm.probs > 0.5,1,0)
# Accuracy
table(glm.preds,responseYtrain)
mean(glm.preds == responseYtrain)
#testing
test <- pc.comp[1:15,1:5]
test_df <- as.data.frame(test)
responseYtest <- M_init[1:15, 17]
glm.probs <- predict(glm.fit,newdata=test_df, type = "response")
?predict
class(glm.fit)
glm.fit <- glm(responseYtrain~train1+train2+train3+train4+train5, family=binomial("logit"))
#glm.fit <- glm(responseYtrain~train1+train2+train3+train4+train5, family=binomial("logit"))
glm.probs <- predict(glm.fit,type = "response")
glm.preds <- ifelse(glm.probs > 0.5,1,0)
# Accuracy
table(glm.preds,responseYtrain)
mean(glm.preds == responseYtrain)
#testing
test <- pc.comp[1:15,1:5]
test_df <- as.data.frame(test)
responseYtest <- M_init[1:15, 17]
glm.probs <- predict(glm.fit,newdata=test_df, type = "response")
