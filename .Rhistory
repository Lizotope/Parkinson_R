sudo apt install gdebi
install.packages("quantmod")
install.packages(c("questionr", "foreign", "readxl", "tidyverse", "ggplot2", "ggrepel", "RColorBrewer", "janitor", "rmarkdown", "knitr", "printr", "broom", "kableExtra", "bookdown", "lmtest", "nnet", "glm2", "ordinal", "FactoMineR", "GDAtools", "cluster", "explor", "factoextra", "TraMineR", "survival", "forecast", "R.temis", "quanteda", "topicmodels", "wordcloud", "network", "sna", "igraph", "tidygraph", "ggraph", "ggmap"))
txtplot(cars[,1], cars[,2], xlab = 'speed', ylab = 'distance')
install.packages("txtplot")
txtplot(cars[,1], cars[,2], xlab = 'speed', ylab = 'distance')
install.packages("car")
install.packages(c("curl", "rio", "car"))
install.packages("txtplot")
txtplot(cars[,1], cars[,2], xlab = 'speed', ylab = 'distance')
library(txtplot)
txtplot(cars[,1], cars[,2], xlab = 'speed', ylab = 'distance')
?distribution
dnorm(-10:10, 0, 1)
x <- seq(-10, 10, 0.01)
y <- dnorm(x)
plot (x,y)
?color
hist(rnorm(1000,0,1),breaks=50)
seed(1,2,3,4,5)
seed(12345)
?seed
??seed
ls
spam7<- read.table("spam7.txt")
spam7<-read.table("spam7.txt")
spam7 <- read.table("~/Documents/MS_Big_Data_TP_et_projets/Data Mining/TP4-Tree/spam7.txt", quote="\"", comment.char="")
View(spam7)
summary(spam7)
spam.sample <- spam7[sample(seq(1,4601),500, replace=FALSE), ]
par(mfrow=c(2,3))
boxplot(split(spam.sample$crl.tot,spam.sample$yesno), main="crl.tot")
boxplot(split(spam.sample$dollar,spam.sample$yesno), main="dollar")
> boxplot(split(spam.sample$bang,spam.sample$yesno), main="bang")
> boxplot(split(spam.sample$money,spam.sample$yesno), main="money")
> boxplot(split(spam.sample$n000,spam.sample$yesno), main="n000")
> boxplot(split(spam.sample$make,spam.sample$yesno), main="make")
boxplot(split(spam.sample$bang,spam.sample$yesno), main="bang")
boxplot(split(spam.sample$money,spam.sample$yesno), main="money")
boxplot(split(spam.sample$n000,spam.sample$yesno), main="n000")
boxplot(split(spam.sample$make,spam.sample$yesno), main="make")
spam6<-spam7[-7]
View(spam6)
reskmeans<-kmeans(spam6,2)
reskmeans
library(cluster)
respam<-pam(spam6,2)
plot(reshc1)
Normaliser crtl.tot permettra de mieux visualiser : quand on regarde plusieurs var, il faut normaliser !
--------------------------------------
spam6N<-scale(spam6)
> boxplot(split(spam.sample$n000,spam.sample$yesno), main="n000")
Normaliser crtl.tot permettra de mieux visualiser : quand on regarde plusieurs var, il faut normaliser !
--------------------------------------
spam6N<-scale(spam6)
library(rpart)
Rspam <- rpart(spam6,2)
Rspam <- rpart(spam7,2)
Rspam <- rpart(spam7,2)
S<-spam7
sub <- c(sample(1:max(which(S$yesno=="y")), round(0.8*max(which(S$yesno=="y")),digits=0)),
sample((max(which(S$yesno=="y"))+1):4601,round(0.8*length(which(S$yesno=="n")),digits=0)))
fit <- rpart(S$yesno~ ., data=S, subset=sub)
plot(fit)
text(fit)
table(predict(fit, S[-sub,], type="class"), S[-sub, "yesno"])
S<-spam7
sub <- c(sample(1:max(which(S$yesno=="y")), round(0.8*max(which(S$yesno=="y")),digits=0)),
sample((max(which(S$yesno=="y"))+1):4601,round(0.8*length(which(S$yesno=="n")),digits=0)))
fit <- rpart(S$yesno~ ., data=S, subset=sub)
plot(fit)
text(fit)
table(predict(fit, S[-sub,], type="class"), S[-sub, "yesno"])
S<-spam7
sub <- c(sample(1:max(which(S$yesno=="y")), round(0.8*max(which(S$yesno=="y")),digits=0)),
sample((max(which(S$yesno=="y"))+1):4601,round(0.8*length(which(S$yesno=="n")),digits=0)))
fit <- rpart(S$yesno~ ., data=S, subset=sub)
plot(fit)
text(fit)
table(predict(fit, S[-sub,], type="class"), S[-sub, "yesno"])
S<-spam7
sub <- c(sample(1:max(which(S$yesno=="y")), round(0.8*max(which(S$yesno=="y")),digits=0)),
sample((max(which(S$yesno=="y"))+1):4601,round(0.8*length(which(S$yesno=="n")),digits=0)))
fit <- rpart(S$yesno~ ., data=S, subset=sub)
fit
plot(fit)
text(fit)
S<-spam7
sub <- c(sample(1:max(which(S$yesno=="y")), round(0.8*max(which(S$yesno=="y")),digits=0)),
sample((max(which(S$yesno=="y"))+1):4601,round(0.8*length(which(S$yesno=="n")),digits=0)))
fit <- rpart(S$yesno~ ., data=S, subset=sub)
fit
plot(fit)
text(fit)
table(predict(fit, S[-sub,], type="class"), S[-sub, "yesno"])
predict(fit, S[-sub,], type="class"), S[-sub, "yesno"]
(24+110)/(534+253)
(24+110)/(921)
(55+72)/(921)
S<-spam7
sub <- c(sample(1:max(which(S$yesno=="y")), round(0.8*max(which(S$yesno=="y")),digits=0)),
sample((max(which(S$yesno=="y"))+1):4601,round(0.8*length(which(S$yesno=="n")),digits=0)))
fit <- rpart(S$yesno~ ., data=S, subset=sub)
fit
plot(fit)
text(fit)
table(predict(fit, S[-sub,], type="class"), S[-sub, "yesno"])
(145)/(921)
# Libraries
library(sm)
library(zoo)
library(ggplot2)
library(vioplot)
library(Hmisc)
library("FactoMineR")
library("factoextra")
library("corrplot")
library(reshape2)
library(plotrix)
library(tidyverse)
library(NbClust)
library(cluster)
getwd()
setwd("/home/liz/Documents/MS_Big_Data_TP_et_projets/Data Mining/Projet/Parkinson_R")
P_init<-read.table("parkinsons.data", header = FALSE, sep = ",", quote = "", dec = ".",
row.names=1, col.names=c("Signal_Id","MDVP_Fo", "MDVP_Fhi", "MDVP_Flow","MDVP_JitterRel",
"MDVP_JitterAbs","MDVP_Rap","MDVP_PPQ","Jitter_DDP",
"MDVP_Shimmer","MDVP_ShimmerDB","Shimmer_APQ3",
"Shimmer_APQ5","MDVP_APQ","Shimmer_DDA","NHR","HNR",
"status","RPDE","DFA","spread1","spread2",
"D2","PPE"),
as.is = FALSE, na.strings = "NA",
colClasses = NA, nrows = -1,
skip = 1, check.names = TRUE, fill = !TRUE,
strip.white = FALSE, blank.lines.skip = TRUE,
comment.char = "#")
# je vérifie le bon nommage des attributs/individus, la dim, le type des attributs
rownames(P_init)    # lines
colnames(P_init)    # columns
names(P_init)       # attributes
dim(P_init)         # dim
str(P_init)         # types
# visualisation en tableau du dataset de travail
View(P_init)
# standardisation des données (Ca va servir pr kmeans, pam et pca)
P_initsc<-scale(P_init)
P_hsc<-scale(P_h)
P_pdsc<-scale(P_pd)
# Split des données patients malades vs.sains pour voir si les outliers seraient
# en lien avec le caractère malade du patient
# P_pd est le dataset contenant les signaux de patients malades
P_pd <- P_init[P_init$status==1,]
describe(P_pd)
# P_h est le dataset contenant les signaux de patients malades
P_h <- P_init[P_init$status==0,]
describe(P_h)
# standardisation des données (Ca va servir pr kmeans, pam et pca)
P_initsc<-scale(P_init)
P_hsc<-scale(P_h)
P_pdsc<-scale(P_pd)
# ANALXSE EN COMPOSANTES PRINCIPALES
################################################################################
# pca sur jeu de données normalisé pour lequel nous avons retiré l'attribut à prédire (la 17è colonne)
res.pca <- PCA(P_initsc[,-17], scale.unit = TRUE, graph = TRUE)
# VARIANCE, VECTEURS PROPRES (=COMPOSANTES PRINCIPALES)
# desc des val propres portant le plus l'information (inertie)
eig.val <- get_eigenvalue(res.pca)
eig.val
# graphique des val propres (screeplot)
fviz_eig(res.pca, addlabels = TRUE, ylim = c(0, 50))
# extraction des résultats de l'ACP
var <- get_pca_var(res.pca)
# ETUDE DES CORRELATIONS DES ATTRIBUTS INITIAUX AUX COMPOSANTES PRINCIPALES
# cosinus carré qui permet le calcul de coordonnées des attributs initaux  qui serviront
# à la visualisation du cercle de corrélation
var$cos2
# cercle des corrélation des attributs initiaux aux composantes principales
# Colorer en fonction du cos2: qualité de représentation
fviz_pca_var(res.pca, col.var = "cos2",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
repel = TRUE # Évite le chevauchement de texte
)
# sur le cercle, on ne peut visualiser que 2 dim (plan!)
# pour visualiser toutes les dimensions de 1 à 5 :
corrplot(var$cos2, is.corr=FALSE)
#
# ETUDE DES CONTRIBUTIONS DES ATTRIBUTS INITIAUX AUX COMPOSANTES PRINCIPALES
# extractions des contributions en %
var$contrib
# on voit que DFA, MDVP_Fo, PRDE ont des gros coeff contributeurs aux nouveaux
#composants
# visu du cercle de contributions : attention, seulement les 2 premières dimensions
#ont représentées
fviz_pca_var(res.pca, col.var = "contrib",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07")
)
# extensions aux 5 composantes
corrplot(var$contrib, is.corr=FALSE)
# Contributions des variables à PC1
fviz_contrib(res.pca, choice = "var", axes = 1, top = 10)
# Contributions des variables à PC2
fviz_contrib(res.pca, choice = "var", axes = 2, top = 10) # MDVP_Fo et MDVP_Flow surpassent toutes les autres
# Contributions des variables à PC3
fviz_contrib(res.pca, choice = "var", axes = 3, top = 10) # D2, DFA, spread2...
# Contributions des variables à PC4
fviz_contrib(res.pca, choice = "var", axes = 4, top = 10) # DFA, Shimmet_APQ5
# Contributions des variables à PC5
fviz_contrib(res.pca, choice = "var", axes = 5, top = 10) # RPDE, DFA, spread2
